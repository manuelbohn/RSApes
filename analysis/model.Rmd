---
title: "RSApes model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(ggalluvial)
library(tidyverse)
library(ggthemes)
library(rwebppl)
library(tidyboot)
library(ggpubr)
```

# Literal Model

## Observed scenarios

```{r}
scenarios <- '

var data = [
  {utterance: {face: "bared" , gesture: "bent" }, context: "positive", relation: "dominant"},
  {utterance: {face: "bared" , gesture: "bent" }, context: "positive", relation: "subordinate"},
  {utterance: {face: "bared" , gesture: "bent" }, context: "negative", relation: "dominant"},
  {utterance: {face: "bared" , gesture: "bent" }, context: "negative", relation: "subordinate"},  
  {utterance: {face: "bared" , gesture: "stretched" }, context: "positive", relation: "dominant"},
  {utterance: {face: "bared" , gesture: "stretched" }, context: "positive", relation: "subordinate"},
  {utterance: {face: "bared" , gesture: "stretched" }, context: "negative", relation: "dominant"},
  {utterance: {face: "bared" , gesture: "stretched" }, context: "negative", relation: "subordinate"},
  {utterance: {face: "hoot" , gesture: "bent" }, context: "positive", relation: "dominant"},
  {utterance: {face: "hoot" , gesture: "bent" }, context: "positive", relation: "subordinate"},  
  {utterance: {face: "hoot" , gesture: "bent" }, context: "negative", relation: "dominant"},
  {utterance: {face: "hoot" , gesture: "bent" }, context: "negative", relation: "subordinate"},
  {utterance: {face: "hoot" , gesture: "stretched" }, context: "positive", relation: "dominant"},
  {utterance: {face: "hoot" , gesture: "stretched" }, context: "positive", relation: "subordinate"},
  {utterance: {face: "hoot" , gesture: "stretched" }, context: "negative", relation: "dominant"},
  {utterance: {face: "hoot" , gesture: "stretched" }, context: "negative", relation: "subordinate"}, 
  {utterance: {face: "neutral" , gesture: "bent" }, context: "positive", relation: "dominant"},
  {utterance: {face: "neutral" , gesture: "bent" }, context: "positive", relation: "subordinate"},
  {utterance: {face: "neutral" , gesture: "bent" }, context: "negative", relation: "dominant"},
  {utterance: {face: "neutral" , gesture: "bent" }, context: "negative", relation: "subordinate"},
  {utterance: {face: "neutral" , gesture: "stretched" }, context: "positive", relation: "dominant"},
  {utterance: {face: "neutral" , gesture: "stretched" }, context: "positive", relation: "subordinate"},
  {utterance: {face: "neutral" , gesture: "stretched" }, context: "negative", relation: "dominant"},
  {utterance: {face: "neutral" , gesture: "stretched" }, context: "negative", relation: "subordinate"}
]

'
```

## Model Utilities

```{r}
utils <- '

var all_reactions = [
  { type: "affiliate" },
  { type: "avoid" }
]

var faceMeaning = function(utterance, reaction){
  utterance.face == "hoot" ? flip(hootMean) ? reaction.type == "avoid" : reaction.type == "affiliate" :
  utterance.face == "bared" ? flip(baredMean) ? reaction.type == "avoid" : reaction.type == "affiliate" :
  utterance.face == "neutral" ? flip() ? reaction.type == "affiliate" : reaction.type == "avoid" :
  false
}

var gesMeaning = function(utterance, reaction){
  utterance.gesture == "stretched" ? flip(stretchMean) ? reaction.type == "avoid" : reaction.type == "affiliate" :
  utterance.gesture == "bent" ? flip(bentMean) ? reaction.type == "avoid" : reaction.type == "affiliate" :
  true
}

'
```

## Literal Listener

```{r}
lit <- '
var literalListener = function(utterance, context, relationship){
  Infer({method: "enumerate", model: function(){
    // building up the prior
    var priorProbContext = (context == "positive") ? contextPrior : 1-contextPrior
    var priorProbRelation = (relationship == "dominant") ? relationPrior : 1-relationPrior
    var priorProbs = normalize([
      priorProbContext * priorProbRelation,
      (1 - priorProbContext) * (1 - priorProbRelation)
    ])
  
  
    // taking in the different parts of the utterance
    var reaction = sample(Categorical({vs: all_reactions, ps: priorProbs}))
    
    var gesTruthValue = gesMeaning(utterance, reaction)
    var faceTruthValue = faceMeaning(utterance, reaction)

    // Do some conditioning I guess
    condition(gesTruthValue)
    condition(faceTruthValue)

    // return the inferred reaction
    return reaction.type
  }})
}

'
```

## Model Parameters

```{r}
parameters <- '

//gesture meanings
var stretchMean = .45
var bentMean = .45

// face meanings
var hootMean = .9
var baredMean = .6
    
  // priors  
var contextPrior = .7
var relationPrior = .25

'
```


## Model Run

```{r}
model <- '

var output = map(function(row){

  var pred = literalListener(row.utterance, row.context, row.relation)
  
   return extend([row.utterance.gesture + "/" + row.utterance.face + "/" + row.context + "/" + row.relation, Math.exp(pred.score("avoid"))])

}, data)

output


'
```


## Model Output

```{r}
model_predictions <- webppl(
  program_code = paste(scenarios, parameters, utils,lit ,model, sep='\n')
)%>%
  separate(`0`, into = c("gesture", "face", "context", "relation"), sep="/")%>%
  rename(prediction = `1`)
```

# Comparing Model to Data

## Read in Data

```{r}
data <- read_xlsx("../data/Rawdata_Compositionality_18122019.xlsx", sheet = 1)
```

We select all scenarios for which we have 5 or more observations.

```{r}
data_agg <- data %>%
  filter(context_dyad!= "NA",
         REACT != "NA",
         rel_dom != "NA", 
         face != "NA",
         GEST != "NA")%>%
  rename(context = context_dyad, 
         relation = rel_dom, 
         gesture = GEST,)%>%
  mutate(pos_react = as.numeric(REACT == "affil"),
         neg_react = as.numeric(REACT == "avoid"))%>%
  group_by(context,relation,face,gesture)%>%
  tidyboot_mean(column = pos_react)%>%
  mutate(affiliate = mean,
         avoid = 1-mean)%>%
  filter(n > 4)%>%
  select(-empirical_stat, mean)%>%
  pivot_longer(names_to = "reaction", values_to = "proportion", cols = c(affiliate,avoid))%>%
  mutate(ci_lower = ifelse(reaction == "avoid", 1- ci_lower, ci_lower),
         ci_upper = ifelse(reaction == "avoid", 1- ci_upper, ci_upper))%>%
  ungroup()%>%
  mutate(context = recode(context, neg = "negative",pos = "positive"),
         relation = recode(relation, todom = "dominant",nottodom = "subordinate"),
         gesture = recode(gesture, SG = "stretched",BG = "bent"))
```

## Plots

### Bar Plot

```{r}
plot <- data_agg%>%
  left_join(model_predictions%>%
             mutate(affiliate = 1-prediction)%>%
             rename(avoid = prediction)%>%
             pivot_longer(names_to = "reaction", values_to = "prediction", cols = c(affiliate,avoid)))

bp <- ggplot(plot, aes(x = gesture, y = proportion))+
  geom_bar(stat = "identity", aes(fill = reaction),position = position_dodge(), alpha = .5, col = "black")+
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, group = reaction), col = "black", position = position_dodge(width = .9), width = 0, size = 1)+
  geom_point(aes(y = prediction, group = reaction), position = position_dodge(width = .9), col = "firebrick", pch = 4, size = 2, stroke = 2)+
  theme_few()+
  facet_grid(relation ~  face)+
  scale_fill_colorblind()+
  scale_color_colorblind()

```

### Correlation

```{r}
cp <- plot%>%
  filter(reaction == "affiliate")%>%
  ggplot(aes(x = proportion, y = prediction))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .5)+
  geom_point(aes(size = n),fill = "firebrick", col = "black", pch = 21,  stroke = 1, alpha = .75)+
  theme_minimal()+
  xlim(0,1)+
  ylim(0,1)+
  #coord_fixed()+
  labs(x = "Data", y = "Model")+
  scale_size(name = "Observations")+
  stat_cor(method = "pearson", aes(x = proportion, y = prediction,label = paste(..r.label..)), inherit.aes = F, size = 4.5, r.accuracy = 0.01, cor.coef.name = "r")+
  theme(panel.border = element_rect(color = "black",fill = NA,size = 1))
```

```{r}
ggarrange(bp,cp, widths = c(1.5,1), labels = c("A","B"))

ggsave("../graphs/model_plot.png", width = 10, height = 3, scale = 1.5)
```

# Reduced models

## Parameters

```{r}
parametersGes <- '

//gesture meanings
var stretchMean = .45
var bentMean = .45

// face meanings
var hootMean = .5
var baredMean = .5
    
  // priors  
var contextPrior = .5
var relationPrior = .5

'
```

```{r}
parametersFace <- '

//gesture meanings
var stretchMean = .5
var bentMean = .5

// face meanings
var hootMean = .9
var baredMean = .6
    
  // priors  
var contextPrior = .5
var relationPrior = .5

'
```

```{r}
parametersContext <- '

//gesture meanings
var stretchMean = .5
var bentMean = .5

// face meanings
var hootMean = .5
var baredMean = .5
    
  // priors  
var contextPrior = .7
var relationPrior = .5
'
```


```{r}
parametersRelation <- '

//gesture meanings
var stretchMean = .5
var bentMean = .5

// face meanings
var hootMean = .5
var baredMean = .5
    
  // priors  
var contextPrior = .5
var relationPrior = .25

'
```

## Model Runs

```{r}
model_predictions_gesture <- webppl(
  program_code = paste(scenarios, parametersGes, utils,lit ,model, sep='\n')
)%>%
  separate(`0`, into = c("gesture", "face", "context", "relation"), sep="/")%>%
  rename(prediction = `1`)

model_predictions_face <- webppl(
  program_code = paste(scenarios, parametersFace, utils,lit ,model, sep='\n')
)%>%
  separate(`0`, into = c("gesture", "face", "context", "relation"), sep="/")%>%
  rename(prediction = `1`)

model_predictions_context <- webppl(
  program_code = paste(scenarios, parametersContext, utils,lit ,model, sep='\n')
)%>%
  separate(`0`, into = c("gesture", "face", "context", "relation"), sep="/")%>%
  rename(prediction = `1`)

model_predictions_relation <- webppl(
  program_code = paste(scenarios, parametersRelation, utils,lit ,model, sep='\n')
)%>%
  separate(`0`, into = c("gesture", "face", "context", "relation"), sep="/")%>%
  rename(prediction = `1`)

reduced_model_predictions <- bind_rows(
  model_predictions_gesture%>%mutate(model = "Gesture Only"),
  model_predictions_face%>%mutate(model = "Face Only"),
  model_predictions_context%>%mutate(model = "Context Only"),
  model_predictions_relation%>%mutate(model = "Relation Only")
)

```

## Plots

### Correlation

```{r}
plotRed <- data_agg%>%
  left_join(reduced_model_predictions%>%
             mutate(affiliate = 1-prediction)%>%
             rename(avoid = prediction)%>%
             pivot_longer(names_to = "reaction", values_to = "prediction", cols = c(affiliate,avoid)))

cpRed <- plotRed%>%
  filter(reaction == "affiliate")%>%
  ggplot(aes(x = proportion, y = prediction))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .5)+
  geom_point(aes(size = n),fill = "#19647E", col = "black", pch = 21,  stroke = 1, alpha = .75)+
  theme_minimal()+
  xlim(0,1)+
  ylim(0,1)+
  facet_grid(~model)+
  labs(x = "Data", y = "Model")+
  scale_size(name = "Observations")+
  stat_cor(method = "pearson", aes(x = proportion, y = prediction,label = paste(..r.label..)), inherit.aes = F, size = 4.5, r.accuracy = 0.01, cor.coef.name = "r",na.rm = T)+
  theme(panel.border = element_rect(color = "black",fill = NA,size = 1))
```

```{r}
ggarrange(ggarrange(bp,cp, widths = c(1.5,1), labels = c("(a)","(b)"), font.label = list(family = "serif", face = "italic")), cpRed, labels = c("","(c)"), heights = c(1.1,1), nrow = 2, font.label = list(family = "serif", face = "italic"))
```

```{r}
ggsave("../graphs/model_plot_comb.png", width = 10, height = 6, scale = 1.25)
```

# Model with alternative parameter settings

## Model Parameters

Flip importance of gestures and facial expressions: Increase strength of "meaning" of gestures and decrease strength of facial expressions. 

```{r}
parametersAlt <- '

//gesture meanings
var stretchMean = .2
var bentMean = .2

// face meanings
var hootMean = .6
var baredMean = .55
    
  // priors  
var contextPrior = .7
var relationPrior = .25

'
```

## Model run

```{r}
model_predictionsAlt <- webppl(
  program_code = paste(scenarios, parametersAlt, utils,lit ,model, sep='\n')
)%>%
  separate(`0`, into = c("gesture", "face", "context", "relation"), sep="/")%>%
  rename(prediction = `1`)
```

### Bar Plot

We select all scenarios for which we have 5 or more observations.

```{r}
plotAlt <- data_agg%>%
  left_join(model_predictionsAlt%>%
             mutate(affiliate = 1-prediction)%>%
             rename(avoid = prediction)%>%
             pivot_longer(names_to = "reaction", values_to = "prediction", cols = c(affiliate,avoid)))

bpAlt <- ggplot(plotAlt, aes(x = gesture, y = proportion))+
  geom_bar(stat = "identity", aes(fill = reaction),position = position_dodge(), alpha = .5, col = "black")+
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, group = reaction), col = "black", position = position_dodge(width = .9), width = 0, size = 1)+
  geom_point(aes(y = prediction, group = reaction), position = position_dodge(width = .9), col = "#19647E", pch = 4, size = 2, stroke = 2)+
  theme_few()+
  facet_grid(relation ~  face)+
  scale_fill_colorblind()+
  scale_color_colorblind()

```

### Correlation

```{r}
cpAlt <- plotAlt%>%
  filter(reaction == "affiliate")%>%
  ggplot(aes(x = proportion, y = prediction))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .5)+
  geom_point(aes(size = n),fill = "#19647E", col = "black", pch = 21,  stroke = 1, alpha = .75)+
  theme_minimal()+
  xlim(0,1)+
  ylim(0,1)+
  #coord_fixed()+
  labs(x = "Data", y = "Model")+
  scale_size(name = "Observations")+
  stat_cor(method = "pearson", aes(x = proportion, y = prediction,label = paste(..r.label..)), inherit.aes = F, size = 4.5, r.accuracy = 0.01, cor.coef.name = "r")
```

```{r}
ggarrange(bpAlt,cpAlt, widths = c(1.5,1))

ggsave("../graphs/model_plot_alternative_parameters.png", width = 10, height = 3, scale = 1.5)
```


# Pragmatic model

Question: How can pragmatics amplify the weak meaning of a gesture?

Focus is on gesture, thus all other parameters are set to .5.


## Speaker

## Pragmatic listener

```{r}
prag <- '

var all_locations = [
  { type: "left" },
  { type: "right" }
]

var pointMeaning = function(utterance, location){
  utterance.point == "left" ? flip(pointStrength) ? location.type == "left" : location.type == "right" :
  utterance.point == "right" ? flip(pointStrength) ? location.type == "right" : location.type == "left" :
  true
}


var literalListener = function(utterance){
  Infer({method: "enumerate", model: function(){
  
    var location = sample(Categorical({vs: all_locations, ps: [0.5,0.5]}))
    
    var gesTruthValue = pointMeaning(utterance, location)

    condition(gesTruthValue)

    return location.type
  }})
}


var utterancePrior = function(){
  var point = uniformDraw(["left", "right"])
  return {point: point}
}


var speaker = function(location, speakerOptimality){
  Infer({method: "enumerate", model: function(){
        
    var utt = utterancePrior()
    var L0 = literalListener(utt);
    
    factor(speakerOptimality * L0.score(location.type))
    
    return utt
  }})
}


var pragmaticListener = function(utterance){
  Infer({method: "enumerate", model: function(){

  var location = sample(Categorical({vs: all_locations, ps: [0.5,0.5]}))
  
  var S1 = speaker(location, speakerOptimality);
  
  observe(S1, utterance)
  
  return location.type
   
  }})
}

'
```

## Model Parameters

`stretchMean` is now taken to represent a gesture (or other type of signal) with only a very weak meaning. 

```{r}
parametersPrag <- '

  //  gesture meanings
    var pointStrength = .53
'
```

```{r}
speakOpt1 <- '

var speakerOptimality = 1
'
```


```{r}
speakOpt5 <- '

var speakerOptimality = 5
'
```

```{r}
speakOpt10 <- '

var speakerOptimality = 10
'
```

## Model Run

```{r}
modelPrag <- '

pragmaticListener({point: "left" })

'
```

```{r}
modelLit <- '

literalListener({point: "left" })

'
```

```{r}
modelSpeak <- '

speaker({ type: "left" }, speakerOptimality)

'
```

## Model Output

```{r}
lit <- webppl(
  program_code = paste(parametersPrag, prag, modelLit, sep='\n')
)

prag1 <- webppl(
  program_code = paste(parametersPrag,speakOpt1, prag, modelPrag, sep='\n')
)

prag5 <- webppl(
  program_code = paste(parametersPrag,speakOpt5, prag, modelPrag, sep='\n')
)

prag10 <- webppl(
  program_code = paste(parametersPrag,speakOpt10, prag, modelPrag, sep='\n')
)

speak5 <- webppl(
  program_code = paste(parametersPrag,speakOpt5, prag, modelSpeak, sep='\n')
)

speak10 <- webppl(
  program_code = paste(parametersPrag,speakOpt10, prag, modelSpeak, sep='\n')
)

pragPlot <- bind_rows(
  lit %>%mutate(model = "literal", alpha = ""),
  prag1 %>%mutate(model = "pragmatic", alpha = "1"),
  prag5 %>%mutate(model = "pragmatic", alpha = "5"),
  prag10 %>%mutate(model = "pragmatic", alpha = "10")
)%>%
  mutate(alpha = factor(alpha, levels = c("NA","1","5","10")))%>%
  filter(support == "left")
```

## Plot

```{r}

ggplot(pragPlot, aes(x = alpha, y = prob))+
  geom_bar(stat = "identity", aes(fill = model, alpha = alpha),position = position_dodge(), col = "black")+
  geom_hline(yintercept = 0.5, lty = 2, alpha = .75)+
  theme_few()+
  facet_grid( ~model, scales = "free_x",space = "free_x")+
  scale_fill_ptol()+
  labs(y = "Proportion gesture congruent choice", x = "Speaker informativeness")+
  guides(fill = "none", alpha = "none")+
  ylim(0,1)

```
```{r}
ggsave("../graphs/model_plot_prag.png", width = 3, height = 3, scale = 1.25)
```
